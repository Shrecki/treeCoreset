{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibertf/nilearn/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import zmq\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import nibabel as nib\n",
    "\n",
    "def compute_outliers_FD(target_file, source, threshold):\n",
    "    mvt_file = pd.read_csv(target_file, header=None, sep='  ') \n",
    "    if source=='FSL':\n",
    "        mvt_file = mvt_file.rename(columns={0: 'Rx', 1: 'Ry', 2: 'Rz', 3: 'Tx', 4: 'Ty', 5: 'Tz'})\n",
    "    else:\n",
    "        mvt_file = mvt_file.rename(columns={3: 'Rx', 4: 'Ry', 5: 'Rz', 0: 'Tx', 1: 'Ty', 2: 'Tz'})\n",
    "    mvt_file[['Rx', 'Ry', 'Rz']] = mvt_file[['Rx', 'Ry', 'Rz']]*180/np.pi\n",
    "    diff_mvt = mvt_file.diff()\n",
    "    diff_mvt.iloc[0]=[0,0,0,0,0,0]\n",
    "    diff_sphere = diff_mvt\n",
    "    diff_sphere[['Rx', 'Ry', 'Rz']] = diff_sphere[['Rx', 'Ry', 'Rz']]*50*np.pi/180\n",
    "    return diff_sphere.abs().sum(axis=1) > threshold\n",
    "\n",
    "def reset_socket(socket):\n",
    "    socket.close()            \n",
    "    socket=context.socket(zmq.REQ)\n",
    "    socket.connect(\"tcp://localhost:5555\")\n",
    "\n",
    "import struct\n",
    "def send_array(socket, array):\n",
    "    socket.send(array.tobytes())\n",
    "    message=socket.recv()\n",
    "    val=struct.unpack('b', message)[0]\n",
    "    if val != 5:\n",
    "        raise NameError('Unexpected response from server')\n",
    "\n",
    "def reduce_array(socket, array):\n",
    "    for f in array:\n",
    "        send_array(socket, np.insert(f,0,0))\n",
    "\n",
    "            \n",
    "def get_representatives(socket):\n",
    "    reps = []\n",
    "    socket.send(np.asarray([11.0]))\n",
    "    message = socket.recv()\n",
    "    payload = np.frombuffer(message, dtype=np.double())\n",
    "    if payload[0] == 6.0:\n",
    "        socket.send(np.asarray([5.0]))\n",
    "        for i in range(0, int(payload[1])):\n",
    "            message=socket.recv()\n",
    "            payload = np.frombuffer(message, dtype = np.double())\n",
    "            reps.append(payload)\n",
    "            socket.send(np.asarray([5.0]))\n",
    "        message = socket.recv()\n",
    "    return np.vstack(reps)\n",
    "\n",
    "\n",
    "def get_array_representatives(array, socket):\n",
    "    reduce_array(socket, array)\n",
    "    reps = get_representatives(socket)\n",
    "    \n",
    "def prepare_confounds(mvt_path, csf_path, wm_path, gm_path, compute_mvt_derivatives=True, compute_mvt_squares=True):\n",
    "    df_orig = pd.read_csv(mvt_path, header=None, sep='  ')\n",
    "    df_data = df_orig.to_numpy()\n",
    "    total_data = df_data.copy()\n",
    "    if csf_path is not None:\n",
    "        csf_signal = pd.read_csv(csf_path, header=None)\n",
    "        total_data = np.hstack((csf_signal.to_numpy(), total_data))\n",
    "    if wm_path is not None:\n",
    "        wm_signal = pd.read_csv(wm_path, header=None)\n",
    "        total_data = np.hstack((wm_signal.to_numpy(), total_data))\n",
    "    if gm_path is not None:\n",
    "        gm_signal = pd.read_csv(gm_path, header=None)\n",
    "        total_data = np.hstack((gm_signal.to_numpy(), total_data))\n",
    "    if compute_mvt_derivatives:\n",
    "        derivatives = np.gradient(df_data)[0]\n",
    "        total_data = np.hstack((total_data, derivatives))\n",
    "    if compute_mvt_squares:\n",
    "        total_data = np.hstack((total_data, df_data**2))\n",
    "        if compute_mvt_derivatives:\n",
    "            total_data = np.hstack((total_data, derivatives**2))\n",
    "    all_confounds = pd.DataFrame(total_data)\n",
    "    return all_confounds\n",
    "    \n",
    "# We would like for each assignement to obtain in what 'state' we were.\n",
    "# To gather statistics, basically.\n",
    "import seaborn as sns\n",
    "\n",
    "def gather_stats_and_plot(hrf_delay, events, k, assignements, x):\n",
    "    \"\"\"\n",
    "    Given an input array of events, along with an input array of CAPs assignement and their associated time array x, the number of CAPs and an HRF delay:\n",
    "    - Assign to each event the assignement that is closest in time (ie: assign the time t that is closest to event time + hrf_delay)\n",
    "    - Aggregate, per CAP, the different events from perspective of behavioural response (error type basically)\n",
    "    - Lastly, plot the results, displaying frequency of each error type per CAP.\n",
    "    :param hrf_delay: \n",
    "    :param events: \n",
    "    :param k: \n",
    "    :param assignements: \n",
    "    :param x: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    gathered_stats = np.zeros((4, k))\n",
    "    get_array_entry = lambda i : (int(events.iloc[i]['trial_type']=='go')<<1) + int(events.iloc[i]['resp_correct'])\n",
    "    for i in range(0, events.shape[0]-1):\n",
    "        time = int(round(events.iloc[i]['onset'] + hrf_delay))\n",
    "        corresp = np.where(x == time)\n",
    "        if corresp[0].size == 0:\n",
    "            print('Time {} not found'.format(time))\n",
    "        centroid = assignements[np.where(x == time)]\n",
    "        gathered_stats[get_array_entry(i), centroid] += 1\n",
    "    cap_arr = []\n",
    "    gathered_stats /= gathered_stats.sum(axis=0)\n",
    "    for i in range(0,k):\n",
    "        cap_arr.extend(['CAP_' + str(i)]*4)\n",
    "    df=pd.DataFrame({'Frequency': gathered_stats.flatten(order='F'), 'Error Type': ['Commission Error', 'Correct Omission', 'Omission Error', 'Correct Commission']*k, 'CAP': cap_arr})\n",
    "    sns.catplot(x='Error Type', hue='CAP', y='Frequency', data=df, kind='bar')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def make_path(subject_name, session_name):\n",
    "    return os.path.join('/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/', 'analysis', subject_name, session_name, 'func', subject_name + '_' + session_name + '_task-gradCPT_bold_masked-fullbrain_zscored_smoothed-5mm_detrended_csf-removed_wm-removed_8volumes-scrubbed.npy')\n",
    "\n",
    "\n",
    "\n",
    "def run_k_means_and_get_assignements(k, reps, sessions):\n",
    "    # Get clusters for a specific k\n",
    "    # Then we can run kmeans on this reduced version\n",
    "    kmeans = KMeans(n_clusters=k) # some k. A relevant question (but to be answered later) is whether consensus clustering might be relevant here or not\n",
    "    kmeans.fit(reps) # compute centroids on reduced data version\n",
    "    # Important: save the CAPs that were found, so they can be inspected.\n",
    "    masker = NiftiMasker(mask_img='/usr/local/fsl/data/standard/MNI152_T1_2mm_brain_mask_dil1.nii.gz')\n",
    "    m = nib.load(masker.mask_img)\n",
    "    for i in range(0,k):\n",
    "        data = m.get_fdata()\n",
    "        data[m.get_fdata().astype(bool)] = reps[i]\n",
    "        nib.save(nib.Nifti1Image(data, m.affine, m.header), '/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/analysis/sub-07/CAPS_' + str(i) + '.nii.gz')\n",
    "    assignements = []\n",
    "    # Now we want to get the assignments for all sessions, using these centroids. To do so, we must reload the data (a tad painful)\n",
    "    for sess in sessions:\n",
    "        session_name = sess.split('/')[-2]\n",
    "        save_path = make_path(subject_name, session_name)\n",
    "        # To get the session, load it from disk\n",
    "        session_data = np.load(save_path)\n",
    "        # Get back motion outliers\n",
    "        mvt_file = glob.glob(os.path.join(sess, 'func','sub*gradCPT*_mcf.txt'))\n",
    "        mvt_file = mvt_file[0]\n",
    "        outliers = compute_outliers_FD(mvt_file, 'FSL', 0.5)[8:]\n",
    "        # Predict only on volumes with decent motion\n",
    "        assignements.append(kmeans.predict(session_data[:,:][np.logical_not(outliers),:].astype(np.double())))\n",
    "        del session_data # We still care about the RAM !\n",
    "    return assignements, kmeans\n",
    "\n",
    "# Get statistics for that k and plot it\n",
    "\n",
    "def get_event_type_id(event):\n",
    "    return 2*int(event['trial_type']=='go') + int(event['resp_correct'])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def gather_stats_for_session(sess_assignements, k, sess_events, hrf_delay=5.0):\n",
    "    times = np.asarray(range(8, 788))\n",
    "    transition_stats = np.zeros((4, k, k))\n",
    "    for e in range(0, sess_events.shape[0]):\n",
    "        t = sess_events.iloc[e]['onset'] + hrf_delay\n",
    "        t_low = int(t)\n",
    "        t_up = t_low + 1\n",
    "        id_up = np.where(times==t_up)[0]\n",
    "        id_low = np.where(times==t_low)[0]\n",
    "        if id_up.size == 0 or id_low.size == 0:\n",
    "            print('No corresp for time interval {}-{}, one of the bounds is missing in EPI time'.format(t_low, t_up))\n",
    "        else:\n",
    "            # Get event type and increment count of transition\n",
    "            transition_stats[get_event_type_id(sess_events.iloc[e]),sess_assignements[id_low], sess_assignements[id_up]] += 1\n",
    "    return transition_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_vector_to_df(binary_vector):\n",
    "    d = {}\n",
    "    for i in range(0, binary_vector.size):\n",
    "        if(binary_vector[i]):\n",
    "            reg = np.zeros((binary_vector.size,))\n",
    "            n = 'outlier_' + str(i)\n",
    "            reg[i] = 1\n",
    "            d[n] = reg\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibertf/nilearn/nilearn/glm/__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n"
     ]
    }
   ],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=1.0,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=True,\n",
    "                           hrf_model='glover + derivative + dispersion',\n",
    "                           drift_model=None,\n",
    "                           high_pass=.01, smoothing_fwhm=5, minimize_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with sub-01...\n",
      "    Analyzing ses-01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-e138e997fbaf>:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  mvt_file = pd.read_csv(target_file, header=None, sep='  ')\n",
      "<ipython-input-1-e138e997fbaf>:62: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_orig = pd.read_csv(mvt_path, header=None, sep='  ')\n",
      "/home/guibertf/nilearn/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `click` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n",
      "/home/guibertf/nilearn/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `resp_correct` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n",
      "/home/guibertf/nilearn/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `response_time` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Saved image to /home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/analysis/sub-01/ses-01/func/go_minus_nogo.nii.gz\n",
      "    Analyzing ses-02...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-e138e997fbaf>:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  mvt_file = pd.read_csv(target_file, header=None, sep='  ')\n",
      "<ipython-input-1-e138e997fbaf>:62: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_orig = pd.read_csv(mvt_path, header=None, sep='  ')\n",
      "/home/guibertf/nilearn/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `click` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n",
      "/home/guibertf/nilearn/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `resp_correct` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n",
      "/home/guibertf/nilearn/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `response_time` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "import gc\n",
    "\n",
    "# We will get the Yeo 7 atlas, to identify signal level in somatomotor region\n",
    "yeo = datasets.fetch_atlas_yeo_2011()\n",
    "atlas_masker = NiftiLabelsMasker(labels_img=yeo['thick_7'], standardize=False,\n",
    "                           memory='nilearn_cache')\n",
    "\n",
    "\n",
    "\n",
    "subject_motor_scores={}\n",
    "subjects='/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/preprocessed/'\n",
    "for subject_path  in sorted(glob.glob(subjects + 'sub*/')):\n",
    "    subject_name = subject_path.split('/')[-2]\n",
    "    sessions = sorted(glob.glob(os.path.join(subject_path, 'ses*/')), key=lambda x: int(x.split('-')[3][:-1]))\n",
    "    print('Starting with ' + subject_name + '...')\n",
    "    behavioural_path = os.path.join('/'.join(subject_path.split('/')[:-4]), subject_name)\n",
    "    behav_sessions = sorted(glob.glob(os.path.join(behavioural_path, 'ses*/')), key=lambda x: int(x.split('-')[3][:-1]))\n",
    "    for i, sess in enumerate(sessions):\n",
    "        session_name = sess.split('/')[-2]\n",
    "        print('    Analyzing ' + session_name + '...')\n",
    "        # Load the data, preprocess it, so on and so forth\n",
    "        mvt_file = glob.glob(os.path.join(sess, 'func','sub*gradCPT*_mcf.txt'))\n",
    "        if len(mvt_file) > 0:\n",
    "            mvt_file = mvt_file[0]\n",
    "            outliers = compute_outliers_FD(mvt_file, 'FSL', 0.5)\n",
    "            # Prepare the confounds to be regressed out: movement parameters, csf signal, white matter signal\n",
    "            confounds = prepare_confounds(mvt_path=mvt_file, csf_path= glob.glob(os.path.join(sess, 'func','sub*gradCPT*_csf.txt'))[0], wm_path= glob.glob(os.path.join(sess, 'func','sub*gradCPT*_wm.txt'))[0], gm_path=None)\n",
    "            # Also add outliers to censor volumes with too much motion\n",
    "            confounds = confounds.join(pd.DataFrame(convert_vector_to_df(outliers)))\n",
    "            # Session data will be zscored, smoothed (5 fwhm mm), linearly detrended. \n",
    "            # To further spare RAM, the input data is restricted to a brain mask, which encompasses entire brain. To minimize odds of throwing away relevant information, we use a dilated version\n",
    "            #masker = NiftiMasker(mask_img='/usr/local/fsl/data/standard/MNI152_T1_2mm_brain_mask_dil1.nii.gz', standardize='zscore', smoothing_fwhm=5, t_r=1, detrend=True)\n",
    "            # Apply the processing pipeline to our input data, at last c:\n",
    "            #session_data = masker.fit_transform(glob.glob(os.path.join(sess, 'func','sub*gradCPT_bold_mni.nii.gz'))[0],confounds=confounds)[8:,:].astype(np.double())\n",
    "            behav_sess = behav_sessions[i]\n",
    "            events=pd.read_csv(glob.glob(os.path.join(behav_sess, 'func', '*gradCPT_events.tsv'))[0], delimiter='\\t')\n",
    "            # fit the GLM, retaining only events which were correct\n",
    "            fit_glm = fmri_glm.fit(glob.glob(os.path.join(sess, 'func','sub*gradCPT_bold_mni.nii.gz'))[0],confounds=confounds,events=events[(events['resp_correct']==1)])\n",
    "            # Now prepare the contrast vector of go - no go\n",
    "            design_mat = fit_glm.design_matrices_[0]\n",
    "            contrast = np.zeros((design_mat.shape[1]))\n",
    "            contrast[design_mat.columns.get_loc('go')]=1\n",
    "            contrast[design_mat.columns.get_loc('nogo')]=-1\n",
    "            # Get the contrast as a Z-score\n",
    "            img=fit_glm.compute_contrast(contrast, output_type='z_score')\n",
    "            # Get somatomotor value of the map\n",
    "            masked_img=atlas_masker.fit_transform(img)\n",
    "            somatomotor_val=masked_img[0,1]\n",
    "            # Save the map to disk\n",
    "            nib.save(img, os.path.join('/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/analysis', subject_name, session_name, 'func/go_minus_nogo.nii.gz'))\n",
    "            print('        Saved image to ' +  os.path.join('/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/analysis', subject_name, session_name, 'func/go_minus_nogo.nii.gz'))\n",
    "            # Save somatomotor value\n",
    "            subject_motor_scores[subject_path + '_' + sess] = somatomotor_val\n",
    "            del masked_img, fit_glm, design_mat, img\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will worry about subject 07 for now, because it has no motion outliers.\n",
    "subject_path = '/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/preprocessed/sub-07/'\n",
    "subject_name = subject_path.split('/')[-2]\n",
    "sessions = sorted(glob.glob(os.path.join(subject_path, 'ses*/')), key=lambda x: int(x.split('-')[3][:-1]))\n",
    "\n",
    "\n",
    "# Now that various sessions have been 'reduced' we lack the centroids. We will compute them in two steps:\n",
    "# Get the various sessions\n",
    "sess = sessions[0]\n",
    "session_name = sess.split('/')[-2]\n",
    "# Load the data, preprocess it, so on and so forth\n",
    "mvt_file = glob.glob(os.path.join(sess, 'func','sub*gradCPT*_mcf.txt'))\n",
    "if len(mvt_file) > 0:\n",
    "    mvt_file = mvt_file[0]\n",
    "    outliers = compute_outliers_FD(mvt_file, 'FSL', 0.5)[8:]\n",
    "    # Prepare the confounds to be regressed out: movement parameters, csf signal, white matter signal\n",
    "    confounds = prepare_confounds(mvt_path=mvt_file, csf_path= glob.glob(os.path.join(sess, 'func','sub*gradCPT*_csf.txt'))[0], wm_path= glob.glob(os.path.join(sess, 'func','sub*gradCPT*_wm.txt'))[0], gm_path=None)\n",
    "    # Session data will be zscored, smoothed (5 fwhm mm), linearly detrended. \n",
    "    # To further spare RAM, the input data is restricted to a brain mask, which encompasses entire brain. To minimize odds of throwing away relevant information, we use a dilated version\n",
    "    masker = NiftiMasker(mask_img='/usr/local/fsl/data/standard/MNI152_T1_2mm_brain_mask_dil1.nii.gz', standardize='zscore', smoothing_fwhm=5, t_r=1, detrend=True)\n",
    "    # Apply the processing pipeline to our input data, at last c:\n",
    "    #session_data = masker.fit_transform(glob.glob(os.path.join(sess, 'func','sub*gradCPT_bold_mni.nii.gz'))[0],confounds=confounds)[8:,:].astype(np.double())\n",
    "\n",
    "\n",
    "behavioural_path = os.path.join('/'.join(subject_path.split('/')[:-4]), subject_name)\n",
    "behav_sessions = sorted(glob.glob(os.path.join(behavioural_path, 'ses*/')), key=lambda x: int(x.split('-')[3][:-1]))\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "behav_sess = behav_sessions[0]\n",
    "events=pd.read_csv(glob.glob(os.path.join(behav_sess, 'func', '*gradCPT_events.tsv'))[0], delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level.hemodynamic_models import _hrf_kernel\n",
    "\n",
    "# We must have an array: [custom_hrf, custom_derivatives, custom_dispersion], basically.\n",
    "# One function per \n",
    "\n",
    "def custom_hrf(hrf_kernel_name, tr, oversampling):\n",
    "    base_kernels=_hrf_kernel(hrf_kernel_name, tr, oversampling, None)[0]\n",
    "    triangular_shape=np.asarray([i if i <= 0.8/0.8 else (1.6-i)/0.8 for i in np.arange(0,1.6,tr/oversampling)])\n",
    "    return np.convolve(triangular_shape, base_kernels, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_spm = lambda tr, oversamp: custom_hrf('spm', tr, oversamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(8, 788)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'26' : identity[0,:], '27' : identity[1,:], '28' : identity[2,:], '29' : identity[3,:], '30' : identity[4,:], '31' : identity[5,:], '32' : identity[6,:], '33' : identity[7,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img=atlas_masker.fit_transform(img)1confounds.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm = fmri_glm.fit(glob.glob(os.path.join(sess, 'func','sub*gradCPT_bold_mni.nii.gz'))[0],confounds=confounds.join(df),events=events[(events['resp_correct']==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import mean_img\n",
    "avg_img = mean_img(glob.glob(os.path.join(sess, 'func','sub*gradCPT_bold_mni.nii.gz'))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm.design_matrices_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat = fit_glm.design_matrices_[0]\n",
    "contrast = np.zeros((design_mat.shape[1]))\n",
    "contrast[design_mat.columns.get_loc('go')]=1\n",
    "contrast[design_mat.columns.get_loc('nogo')]=-1\n",
    "img=fit_glm.compute_contrast(contrast, output_type='z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm.design_matrices_[0].columns.get_loc('nogo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(img, bg_img=avg_img, threshold=1.1, display_mode='z', black_bg=True, title='Go - nogo contrast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "yeo = datasets.fetch_atlas_yeo_2011()\n",
    "\n",
    "atlas_masker = NiftiLabelsMasker(labels_img=yeo['thick_7'], standardize=False,\n",
    "                           memory='nilearn_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img=atlas_masker.fit_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeo['colors_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "nib.save(img,'/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/analysis/sub-07/ses-01/func/go-minus-nogo_contrast.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn import input_data\n",
    "\n",
    "table = get_clusters_table(img, stat_threshold=3.1,\n",
    "                           cluster_threshold=20).set_index('Cluster ID', drop=True)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = table.loc[range(1, 7), ['X', 'Y', 'Z']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = input_data.NiftiSpheresMasker(coords, standardize=True, detrend=True, t_r=1.0, smoothing_fwhm=5.0)\n",
    "\n",
    "real_timeseries = masker.fit_transform(glob.glob(os.path.join(sess, 'func','sub*gradCPT_bold_mni.nii.gz'))[0], confounds=confounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = input_data.NiftiSpheresMasker(coords)\n",
    "predicted_timeseries = masker.fit_transform(fit_glm.predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_timeseries[:,5], label='Predicted')\n",
    "plt.plot(real_timeseries[:,5], label='Real')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level.hemodynamic_models import _sample_condition\n",
    "from nilearn.glm.first_level.experimental_paradigm import check_events\n",
    "events_shifted_corr = events_shifted[events_shifted['resp_correct']==1]\n",
    "trial_type, onset, duration, modulation = check_events(events_shifted_corr)\n",
    "condition=events['trial_type']=='go'\n",
    "exp_condition = (onset[condition], duration[condition],modulation[condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.vstack(((filtered_events['onset']-8).to_numpy(), np.zeros((filtered_events['onset'].size)),np.ones((filtered_events['onset'].size))))\n",
    "np.savetxt(\"/home/guibertf/Documents/Freya/2021-Esterman_InOutZone/niftifiles_GVA_2020/derivatives/analysis/sub-07/ses-01/func/nogo-events.csv\", a.T, delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm = fmri_glm.fit(glob.glob(os.path.join(sess, 'func','sub*gradCPT_bold_mni.nii.gz'))[0],confounds=confounds,events=events[(events['trial_type']=='no-go') & (events['resp_correct']==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(img, bg_img=avg_img, threshold=1.0, display_mode='z', black_bg=True, title='No go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level.hemodynamic_models import _sample_condition\n",
    "from nilearn.glm.first_level.experimental_paradigm import check_events\n",
    "\n",
    "events_corr = events[events['resp_correct']==1].iloc[1:2]\n",
    "trial_type, onset, duration, modulation = check_events(events_corr)\n",
    "condition=events_corr['trial_type']=='go'\n",
    "exp_condition = (onset[condition], duration[condition],modulation[condition])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hrf_kernel(custom_spm, 1.0, 50, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[(events['trial_type']=='no-go') & (events['resp_correct']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm.design_matrices_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_glm.design_matrices_[0]['nogo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm.design_matrices_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = np.zeros((fit_glm.design_matrices_[0].shape[1]))\n",
    "contrast[0]=1\n",
    "img=fit_glm.compute_contrast(contrast, output_type='z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_count=0\n",
    "nogo_count = 0\n",
    "for i in range(0, events_shifted.shape[0]):\n",
    "    t = events_shifted.iloc[i]['trial_type']\n",
    "    if t== 'go':\n",
    "        events_shifted.trial_type.iloc[i]=t+'_'+str(go_count)\n",
    "        go_count+=1\n",
    "    else:\n",
    "        events_shifted.trial_type.iloc[i]=t+'_'+str(nogo_count)\n",
    "        nogo_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "design_matrix = make_first_level_design_matrix(np.arange(0,788,0.8), events=events_shifted[['onset','duration','trial_type']][events_shifted['resp_correct']==1], hrf_model='spm', drift_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "plot_design_matrix(design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are using the custom HRF (which models triangular shapes instead of boxcar shapes), then we must shift back the onset timings by 0.8 seconds (from their max amplitude to their actual starting point)\n",
    "events_shifted=events.copy()\n",
    "events_shifted['onset']-=0.8\n",
    "events_shifted['duration']+=1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_shifted[['onset','duration','trial_type']][events_shifted['resp_correct']==1]['trial_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogo_count+go_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm.design_matrices_[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols=fit_glm.design_matrices_[0].columns[:-42]\n",
    "go_entries = np.zeros(fit_glm.design_matrices_[0].shape[1])\n",
    "nogo_entries = np.zeros(fit_glm.design_matrices_[0].shape[1])\n",
    "\n",
    "go_c_count = 0\n",
    "nogo_c_count = 0\n",
    "for i,f in enumerate(relevant_cols):\n",
    "    if f[:2]=='go':\n",
    "        go_entries[i] = 1\n",
    "        go_c_count += 1\n",
    "    else:\n",
    "        nogo_entries[i]=1\n",
    "        nogo_c_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_entries_single = np.zeros(fit_glm.design_matrices_[0].shape[1])\n",
    "go_entries_single[0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogo_entries_singles = np.zeros(fit_glm.design_matrices_[0].shape[1])\n",
    "nogo_entries_singles[np.where(nogo_entries)[0][0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(go_entries/go_entries.sum() - nogo_entries/nogo_entries.sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_col=[0]*fit_glm.design_matrices_[0].shape[1]\n",
    "go_col[0]=1\n",
    "\n",
    "nogo_col=[0]*fit_glm.design_matrices_[0].shape[1]\n",
    "nogo_col[1]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(go_entries*nogo_entries.sum() - nogo_entries*go_entries.sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "plot_contrast_matrix(go_entries_single - nogo_entries_singles, design_matrix=fit_glm.design_matrices_[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = fit_glm.compute_contrast(go_entries_single - nogo_entries_singles, output_type='z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
